{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/76024851/9655481\n",
    "# %pip install --upgrade jupyter ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Word:\n",
    "    word: str\n",
    "    phonetic: str\n",
    "\n",
    "@dataclass\n",
    "class WordIpaChars:\n",
    "    word: str\n",
    "    ipa: str\n",
    "    ipa_chars: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/51593236/9655481\n",
    "def print_full(dataframe):\n",
    "    pd.set_option(\"display.max_rows\", None)\n",
    "    pd.set_option(\"display.max_columns\", None)\n",
    "    pd.set_option(\"display.width\", 2000)\n",
    "    pd.set_option(\"display.float_format\", \"{:20,.2f}\".format)\n",
    "    pd.set_option(\"display.max_colwidth\", None)\n",
    "    display(dataframe)\n",
    "    pd.reset_option(\"display.max_rows\")\n",
    "    pd.reset_option(\"display.max_columns\")\n",
    "    pd.reset_option(\"display.width\")\n",
    "    pd.reset_option(\"display.float_format\")\n",
    "    pd.reset_option(\"display.max_colwidth\")\n",
    "\n",
    "def show_words(words: List[Word]):\n",
    "    df = pd.DataFrame([vars(word) for word in words])\n",
    "    print_full(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üßë‚Äçüíª **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_words():\n",
    "    with open(\"../data/ipa/fr_FR.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    data = data[\"fr_FR\"][0]\n",
    "    return np.array([Word(key, value) for key, value in data.items()])\n",
    "\n",
    "def get_random_words(n):\n",
    "    words = get_all_words()\n",
    "    rng = np.random.default_rng()\n",
    "    return rng.choice(words, n, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>phonetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>animera</td>\n",
       "      <td>/anim…ô Åa/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>opticiennes</td>\n",
       "      <td>/…îptisj…õn/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>calories</td>\n",
       "      <td>/kal…î Åi/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>impropres</td>\n",
       "      <td>/…õÃÉp Å…îp Å/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mus√¢mes</td>\n",
       "      <td>/myzam/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t√©l√©phon√©es</td>\n",
       "      <td>/telef…îne/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>poissent</td>\n",
       "      <td>/pwas/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abordiez</td>\n",
       "      <td>/ab…î Ådje/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ruisselet</td>\n",
       "      <td>/ Å…•isl…õ/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>encrassait</td>\n",
       "      <td>/…ëÃÉk Åas…õ/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>peseuses</td>\n",
       "      <td>/p…ôz√∏z/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>coiffe</td>\n",
       "      <td>/kwaf/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>√©cumassions</td>\n",
       "      <td>/ekymasj…îÃÉ/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rembruni</td>\n",
       "      <td>/ Å…ëÃÉb Åyni/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>d√©passionnas</td>\n",
       "      <td>/depasj…îna/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>transmuerait</td>\n",
       "      <td>/t Å…ëÃÉsmy Å…õ/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>livr√¢tes</td>\n",
       "      <td>/liv Åat/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>conc√©dassiez</td>\n",
       "      <td>/k…îÃÉsedasje/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>moyennant</td>\n",
       "      <td>/mwaj…õn…ëÃÉ/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>diversifi√©e</td>\n",
       "      <td>/div…õ Åsifje/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word      phonetic\n",
       "0        animera     /anim…ô Åa/\n",
       "1    opticiennes    /…îptisj…õn/\n",
       "2       calories      /kal…î Åi/\n",
       "3      impropres     /…õÃÉp Å…îp Å/\n",
       "4        mus√¢mes       /myzam/\n",
       "5    t√©l√©phon√©es    /telef…îne/\n",
       "6       poissent        /pwas/\n",
       "7       abordiez     /ab…î Ådje/\n",
       "8      ruisselet      / Å…•isl…õ/\n",
       "9     encrassait     /…ëÃÉk Åas…õ/\n",
       "10      peseuses       /p…ôz√∏z/\n",
       "11        coiffe        /kwaf/\n",
       "12   √©cumassions   /ekymasj…îÃÉ/\n",
       "13      rembruni    / Å…ëÃÉb Åyni/\n",
       "14  d√©passionnas   /depasj…îna/\n",
       "15  transmuerait   /t Å…ëÃÉsmy Å…õ/\n",
       "16      livr√¢tes      /liv Åat/\n",
       "17  conc√©dassiez  /k…îÃÉsedasje/\n",
       "18     moyennant    /mwaj…õn…ëÃÉ/\n",
       "19   diversifi√©e  /div…õ Åsifje/"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = get_random_words(20)\n",
    "show_words(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n  g  …™  e  s  o   É  x  t  ≈ã  v  Àê  z  √∏  u     y  .  r  l  j  …•  …≤  …ô  b  d  f  /  ÃÉ   Å  …î  p  …õ  k   ä  i   º  ≈ì  m   í  w  ,  a  …ë\n"
     ]
    }
   ],
   "source": [
    "def find_unique_phonetic_symbols():\n",
    "    \"\"\"\n",
    "    Returns the set of all unique phonetic letters in the dataset.\n",
    "\n",
    "    Note that one word consists of a sequence of phonetic symbols.\n",
    "    \"\"\"\n",
    "    data = get_all_words()\n",
    "    phonetic_symbols = set()\n",
    "    for word in data:\n",
    "        phonetic_symbols.update(set(word.phonetic))\n",
    "    return phonetic_symbols\n",
    "\n",
    "unique = find_unique_phonetic_symbols()\n",
    "print(\"  \".join(unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a phonetic similarity matrix that I can print out and fill out by hand\n",
    "# to assign similarity scores to phonetic symbols. Note that the `unique` variable\n",
    "# contains all unique phonetic symbols in the dataset.\n",
    "similarity_matrix = pd.DataFrame(index=list(unique), columns=list(unique))\n",
    "similarity_matrix = similarity_matrix.fillna(\" \")\n",
    "\n",
    "# store as pdf\n",
    "similarity_matrix.to_html(\"similarity_matrix.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'd', 'f', 'g', 'k', 'l', 'm', 'n', 'p', 's', 't', 'v', 'z', '…≤', ' Å', ' É', ' í', 'd í', 't É', '≈ã', 'j', 'w', '…•', 'a', '…ë', 'e', 'i', 'o', 'u', 'y', '√∏', '≈ì', '…î', '…ô', '…õ', '…ëÃÉ', '…îÃÉ', '…õÃÉ', '≈ìÃÉ']\n"
     ]
    }
   ],
   "source": [
    "# https://easypronunciation.com/en/french-letters-pronunciation-ipa-chart#french_consonants\n",
    "# https://en.wikipedia.org/wiki/Help:IPA/French\n",
    "\n",
    "# Fill out the similarity matrix by hand\n",
    "consonants = [\n",
    "    \"b\",\n",
    "    \"d\",\n",
    "    \"f\",\n",
    "    \"g\",\n",
    "    \"k\",\n",
    "    \"l\",\n",
    "    \"m\",\n",
    "    \"n\",\n",
    "    \"p\",\n",
    "    \"s\",\n",
    "    \"t\",\n",
    "    \"v\",\n",
    "    \"z\",\n",
    "    \"…≤\",\n",
    "    \" Å\",\n",
    "    \" É\",\n",
    "    \" í\",\n",
    "    \"d í\",\n",
    "    \"t É\",\n",
    "    \"≈ã\",\n",
    "]\n",
    "semi_vowels = [\"j\", \"w\", \"…•\"]\n",
    "oral_vowels = [\"a\", \"…ë\", \"e\", \"i\", \"o\", \"u\", \"y\", \"√∏\", \"≈ì\", \"…î\", \"…ô\", \"…õ\"]\n",
    "nasal_vowels = [\"…ëÃÉ\", \"…îÃÉ\", \"…õÃÉ\", \"≈ìÃÉ\"]\n",
    "\n",
    "all_symbols = consonants + semi_vowels + oral_vowels + nasal_vowels\n",
    "print(all_symbols)\n",
    "\n",
    "similarity_matrix = pd.DataFrame(index=list(all_symbols), columns=list(all_symbols))\n",
    "similarity_matrix = similarity_matrix.fillna(\"\")\n",
    "similarity_matrix.to_html(\"similarity_matrix.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí® **Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class SimilarityMatrix:\n",
    "    \"\"\"\n",
    "    Similarity matrix between phonetic symbols.\n",
    "    Can be indexed by two phonetic symbols to get the similarity score between them.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, similarity_data):\n",
    "        all_symbols = self._data_to_symbols(similarity_data)\n",
    "        self.matrix = pd.DataFrame(index=list(all_symbols), columns=list(all_symbols))\n",
    "\n",
    "        for (symbol1, symbol2), score in similarity_data.items():\n",
    "            self.matrix.at[symbol1, symbol2] = score\n",
    "            self.matrix.at[symbol2, symbol1] = score  # symmetric\n",
    "\n",
    "        # Error if matrix contains NaN values\n",
    "        if self.matrix.isnull().values.any():\n",
    "            raise ValueError(\n",
    "                \"Similarity matrix contains NaN values.\"\n",
    "                + \" Make sure to fill out all values.\"\n",
    "            )\n",
    "\n",
    "    def _data_to_symbols(self, data):\n",
    "        symbols = set()\n",
    "        for (symbol1, symbol2), _score in data.items():\n",
    "            symbols.add(symbol1)\n",
    "            symbols.add(symbol2)\n",
    "        return symbols\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.matrix.at[key[0], key[1]]\n",
    "    \n",
    "    def symbols(self):\n",
    "        return list(self.matrix.columns)\n",
    "\n",
    "\n",
    "class NeedlemanWunsch:\n",
    "    \"\"\"\n",
    "    Implementation of the Needleman-Wunsch algorithm for global sequence alignment\n",
    "    score calculation. The algorithm uses a similarity matrix and a linear gap penalty.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, similarity_matrix, gap_penalty):\n",
    "        self.similarity_matrix = similarity_matrix\n",
    "        self.gap_penalty = gap_penalty\n",
    "\n",
    "    def calculate_score(self, a: List[str], b: List[str]):\n",
    "        \"\"\"\n",
    "        Calculates the alignment score between two sequences a and b.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        matrix = np.zeros((len(a) + 1, len(b) + 1))\n",
    "        for i in range(len(a) + 1):\n",
    "            matrix[i, 0] = self.gap_penalty * i\n",
    "        for j in range(len(b) + 1):\n",
    "            matrix[0, j] = self.gap_penalty * j\n",
    "        for i in range(1, len(a) + 1):\n",
    "            for j in range(1, len(b) + 1):\n",
    "                match = matrix[i - 1, j - 1] + self.similarity_matrix[a[i-1], b[j-1]]\n",
    "                delete = matrix[i - 1, j] + self.gap_penalty\n",
    "                insert = matrix[i, j - 1] + self.gap_penalty\n",
    "                matrix[i, j] = max(match, delete, insert)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Time taken: {(end_time - start_time) * 1000} ms\")\n",
    "        \n",
    "        return matrix[-1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allowed symbols: ['A', 'G', 'T', 'C']\n",
      "üåü Score: 49.0\n"
     ]
    }
   ],
   "source": [
    "similarity_data = {\n",
    "    (\"A\", \"A\"): 10,\n",
    "    (\"A\", \"G\"): -1,\n",
    "    (\"A\", \"C\"): -3,\n",
    "    (\"A\", \"T\"): -4,\n",
    "    (\"G\", \"G\"): 7,\n",
    "    (\"G\", \"C\"): -5,\n",
    "    (\"G\", \"T\"): -3,\n",
    "    (\"C\", \"C\"): 9,\n",
    "    (\"C\", \"T\"): 0,\n",
    "    (\"T\", \"T\"): 8,\n",
    "}\n",
    "\n",
    "# similarity_data = {\n",
    "#     (\"A\", \"A\"): 1,\n",
    "#     (\"A\", \"G\"): -1,\n",
    "#     (\"A\", \"C\"): -1,\n",
    "#     (\"A\", \"T\"): -1,\n",
    "#     (\"G\", \"G\"): 1,\n",
    "#     (\"G\", \"C\"): -1,\n",
    "#     (\"G\", \"T\"): -1,\n",
    "#     (\"C\", \"C\"): 1,\n",
    "#     (\"C\", \"T\"): -1,\n",
    "#     (\"T\", \"T\"): 1,\n",
    "# }\n",
    "\n",
    "similarity_matrix = SimilarityMatrix(similarity_data)\n",
    "allowed_symbols = similarity_matrix.symbols()\n",
    "score = NeedlemanWunsch(similarity_matrix, -1).calculate_score(\"GCATGCG\", \"GCATGCA\")\n",
    "print(f\"Allowed symbols: {allowed_symbols}\")\n",
    "print(f\"üåü Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prepare phonetics data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Phonetics:\n",
    "\n",
    "    @classmethod\n",
    "    def preprocess(cls, string) -> List[str]:\n",
    "        \"\"\"\n",
    "        Preprocesses a word by converting it to lowercase and removing whitespace.\n",
    "        \"\"\"\n",
    "        return [cls._preprocess(individual) for individual in string.split(\",\")]\n",
    "\n",
    "    @classmethod\n",
    "    def _preprocess(cls, string) -> str:\n",
    "        res = string.strip()\n",
    "        if res[0] == \"/\":\n",
    "            res = res[1:]\n",
    "        if res[-1] == \"/\":\n",
    "            res = res[:-1]\n",
    "        return res\n",
    "\n",
    "    @classmethod\n",
    "    def split(cls, string, allowed_symbols) -> List[str]:\n",
    "        \"\"\"\n",
    "        Extracts the phonetic symbols from a word by means of a small 1-look-ahead parser.\n",
    "        \"\"\"\n",
    "        symbols = []\n",
    "\n",
    "        i = 0\n",
    "        while i < len(string):\n",
    "            letter = string[i]\n",
    "\n",
    "            # Ignore these symbols\n",
    "            if letter in [\"Àê\", \".\", \" º\", \" \"]:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            if letter not in allowed_symbols:\n",
    "                raise ValueError(f\"Invalid symbol '{letter}' in word '{string}'.\")\n",
    "\n",
    "            if letter == \"\\u0303\":\n",
    "                raise ValueError(\"Unicode 'Combining tilde' character should have been subsumed into the previous character.\")\n",
    "\n",
    "            if i + 1 < len(string):\n",
    "                next_letter = string[i + 1]\n",
    "                if letter in [\"…ë\", \"…õ\", \"…î\", \"≈ì\"] and next_letter == \"\\u0303\":\n",
    "                    symbols.append(letter + u\"\\u0303\")\n",
    "                    i += 2\n",
    "                    continue\n",
    "\n",
    "                if letter == \"d\" and next_letter == \" í\":\n",
    "                    symbols.append(\"d í\")\n",
    "                    i += 2\n",
    "                    continue\n",
    "\n",
    "                if letter == \"t\" and next_letter == \" É\":\n",
    "                    symbols.append(\"t É\")\n",
    "                    i += 2\n",
    "                    continue\n",
    "\n",
    "            symbols.append(string[i])\n",
    "            i += 1\n",
    "\n",
    "        return symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_allowed_symbols = [\n",
    "    \"b\",\n",
    "    \"d\",\n",
    "    \"f\",\n",
    "    \"g\",\n",
    "    \"k\",\n",
    "    \"l\",\n",
    "    \"m\",\n",
    "    \"n\",\n",
    "    \"p\",\n",
    "    \"s\",\n",
    "    \"t\",\n",
    "    \"v\",\n",
    "    \"z\",\n",
    "    \"…≤\",\n",
    "    \" Å\",\n",
    "    \" É\",\n",
    "    \" í\",\n",
    "    \"d í\",\n",
    "    \"t É\",\n",
    "    \"≈ã\",\n",
    "    \"j\",\n",
    "    \"w\",\n",
    "    \"…•\",\n",
    "    \"a\",\n",
    "    \"…ë\",\n",
    "    \"e\",\n",
    "    \"i\",\n",
    "    \"o\",\n",
    "    \"u\",\n",
    "    \"y\",\n",
    "    \"√∏\",\n",
    "    \"≈ì\",\n",
    "    \"…î\",\n",
    "    \"…ô\",\n",
    "    \"…õ\",\n",
    "    \"…ëÃÉ\",\n",
    "    \"…îÃÉ\",\n",
    "    \"…õÃÉ\",\n",
    "    \"≈ìÃÉ\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aok≈ìÃÉm…îm…ëÃÉ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a', 'o', 'k', '≈ìÃÉ', 'm', '…î', 'm', '…ëÃÉ']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonetic = \"aok≈ìÃÉm…îm…ëÃÉ\"\n",
    "phonetics_processed = Phonetics.preprocess(phonetic)\n",
    "print(phonetics_processed)\n",
    "Phonetics.split(phonetics_processed[0], french_allowed_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pickle data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_ipas = []\n",
    "\n",
    "words = get_all_words()\n",
    "for i, word in enumerate(words):\n",
    "    words_processed = Phonetics.preprocess(word.phonetic)\n",
    "    for word_processed in words_processed:\n",
    "        chars = Phonetics.split(word_processed, french_allowed_symbols)\n",
    "        to_append = WordIpaChars(word.word, word_processed, chars)\n",
    "        processed_ipas.append(to_append)\n",
    "\n",
    "with open(\"../data/ipa/fr_FR.pkl\", \"wb\") as f:\n",
    "    pickle.dump(processed_ipas, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß¨ **Calculate scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245646"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/ipa/fr_FR.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "french_allowed_symbols = [\n",
    "    \"b\",\n",
    "    \"d\",\n",
    "    \"f\",\n",
    "    \"g\",\n",
    "    \"k\",\n",
    "    \"l\",\n",
    "    \"m\",\n",
    "    \"n\",\n",
    "    \"p\",\n",
    "    \"s\",\n",
    "    \"t\",\n",
    "    \"v\",\n",
    "    \"z\",\n",
    "    \"…≤\",\n",
    "    \" Å\",\n",
    "    \" É\",\n",
    "    \" í\",\n",
    "    \"d í\",\n",
    "    \"t É\",\n",
    "    \"≈ã\",\n",
    "    \"j\",\n",
    "    \"w\",\n",
    "    \"…•\",\n",
    "    \"a\",\n",
    "    \"…ë\",\n",
    "    \"e\",\n",
    "    \"i\",\n",
    "    \"o\",\n",
    "    \"u\",\n",
    "    \"y\",\n",
    "    \"√∏\",\n",
    "    \"≈ì\",\n",
    "    \"…î\",\n",
    "    \"…ô\",\n",
    "    \"…õ\",\n",
    "    \"…ëÃÉ\",\n",
    "    \"…îÃÉ\",\n",
    "    \"…õÃÉ\",\n",
    "    \"≈ìÃÉ\",\n",
    "]\n",
    "len(french_allowed_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allowed symbols: ['g', 'n', 'e', 's', 'o', ' É', 't', '≈ã', 'v', 'z', '√∏', 't É', 'u', 'y', 'l', 'j', '…•', '…≤', '…ô', 'b', 'd', 'f', ' Å', '…îÃÉ', '≈ìÃÉ', 'p', '…î', '…õ', 'k', '…ëÃÉ', 'i', 'd í', '≈ì', 'm', '…õÃÉ', ' í', 'w', 'a', '…ë']\n",
      "üåü Score: 8.0\n"
     ]
    }
   ],
   "source": [
    "# Open from pickle\n",
    "with open(\"../data/ipa/fr_FR_similarity_costs.pkl\", \"rb\") as f:\n",
    "    french_similarity_costs = pickle.load(f)\n",
    "french_similarity_matrix = SimilarityMatrix(french_similarity_costs)\n",
    "allowed_symbols = french_similarity_matrix.symbols()\n",
    "print(f\"Allowed symbols: {allowed_symbols}\")\n",
    "\n",
    "test_word = Phonetics.split(Phonetics.preprocess(\"snifasje\")[0], french_allowed_symbols)\n",
    "test_word2 = Phonetics.split(Phonetics.preprocess(\"sniaasja\")[0], french_allowed_symbols)\n",
    "\n",
    "score = NeedlemanWunsch(french_similarity_matrix, -1).calculate_score(\n",
    "    test_word, test_word2\n",
    ")\n",
    "print(f\"üåü Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now for real**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allowed symbols: ['g', 'n', 'e', 's', 'o', ' É', 't', '≈ã', 'v', 'z', '√∏', 't É', 'u', 'y', 'l', 'j', '…•', '…≤', '…ô', 'b', 'd', 'f', ' Å', '…îÃÉ', '≈ìÃÉ', 'p', '…î', '…õ', 'k', '…ëÃÉ', 'i', 'd í', '≈ì', 'm', '…õÃÉ', ' í', 'w', 'a', '…ë']\n",
      "0\n",
      "Time taken: 0.3204345703125 ms\n",
      "Time taken: 0.21576881408691406 ms\n",
      "Time taken: 0.1957416534423828 ms\n",
      "Time taken: 0.16427040100097656 ms\n",
      "Time taken: 0.18477439880371094 ms\n",
      "Time taken: 0.11706352233886719 ms\n",
      "Time taken: 0.09083747863769531 ms\n",
      "Time taken: 0.11038780212402344 ms\n",
      "Time taken: 0.10991096496582031 ms\n",
      "Time taken: 0.17309188842773438 ms\n",
      "1\n",
      "Time taken: 0.38552284240722656 ms\n",
      "Time taken: 0.22983551025390625 ms\n",
      "Time taken: 0.2014636993408203 ms\n",
      "Time taken: 0.20647048950195312 ms\n",
      "Time taken: 0.12087821960449219 ms\n",
      "Time taken: 0.1163482666015625 ms\n",
      "Time taken: 0.14328956604003906 ms\n",
      "Time taken: 0.14281272888183594 ms\n",
      "Time taken: 0.560760498046875 ms\n",
      "2\n",
      "Time taken: 1.0423660278320312 ms\n",
      "Time taken: 0.4165172576904297 ms\n",
      "Time taken: 0.5002021789550781 ms\n",
      "Time taken: 0.3247261047363281 ms\n",
      "Time taken: 0.3247261047363281 ms\n",
      "Time taken: 0.4143714904785156 ms\n",
      "Time taken: 0.3933906555175781 ms\n",
      "Time taken: 0.5276203155517578 ms\n",
      "3\n",
      "Time taken: 0.2582073211669922 ms\n",
      "Time taken: 0.3020763397216797 ms\n",
      "Time taken: 0.2257823944091797 ms\n",
      "Time taken: 0.21910667419433594 ms\n",
      "Time taken: 0.2579689025878906 ms\n",
      "Time taken: 0.3006458282470703 ms\n",
      "Time taken: 0.2887248992919922 ms\n",
      "4\n",
      "Time taken: 0.3235340118408203 ms\n",
      "Time taken: 0.19288063049316406 ms\n",
      "Time taken: 0.22554397583007812 ms\n",
      "Time taken: 0.2684593200683594 ms\n",
      "Time taken: 0.18548965454101562 ms\n",
      "Time taken: 9.671449661254883 ms\n",
      "5\n",
      "Time taken: 0.18548965454101562 ms\n",
      "Time taken: 0.1735687255859375 ms\n",
      "Time taken: 0.23245811462402344 ms\n",
      "Time taken: 0.2028942108154297 ms\n",
      "Time taken: 0.23508071899414062 ms\n",
      "6\n",
      "Time taken: 0.26535987854003906 ms\n",
      "Time taken: 0.2262592315673828 ms\n",
      "Time taken: 0.2739429473876953 ms\n",
      "Time taken: 0.25653839111328125 ms\n",
      "7\n",
      "Time taken: 0.2982616424560547 ms\n",
      "Time taken: 0.2510547637939453 ms\n",
      "Time taken: 0.3070831298828125 ms\n",
      "8\n",
      "Time taken: 0.23102760314941406 ms\n",
      "Time taken: 0.331878662109375 ms\n",
      "9\n",
      "Time taken: 0.3635883331298828 ms\n"
     ]
    }
   ],
   "source": [
    "# Open from pickle\n",
    "with open(\"../data/ipa/fr_FR_similarity_costs.pkl\", \"rb\") as f:\n",
    "    french_similarity_costs = pickle.load(f)\n",
    "french_similarity_matrix = SimilarityMatrix(french_similarity_costs)\n",
    "allowed_symbols = french_similarity_matrix.symbols()\n",
    "print(f\"Allowed symbols: {allowed_symbols}\")\n",
    "\n",
    "# Calculate the score for every possible combination of two words.\n",
    "# Take into account the symmetry, i.e. don't calculate the score for the same pair twice.\n",
    "output = []\n",
    "for i, word in enumerate(data[3000:3010]):\n",
    "    print(i)\n",
    "    for j, word2 in enumerate(data[3000:3010]):\n",
    "        if j < i:\n",
    "            continue\n",
    "        score = NeedlemanWunsch(french_similarity_matrix, -1).calculate_score(\n",
    "            word.ipa_chars, word2.ipa_chars\n",
    "        )\n",
    "        output.append((word.word, word.ipa, word2.word, word2.ipa, score))\n",
    "\n",
    "# df = pd.DataFrame(output, columns=[\"word1\", \"word1-ipa\", \"word2\", \"word2-ipa\", \"score\"])\n",
    "# df.to_csv(\"../data/ipa/graph.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
